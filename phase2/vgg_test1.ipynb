{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/projectnb/ece601/kaggle-pulmonary-embolism/rsna-str-pulmonary-embolism-detection/'\n",
    "train_csv = data_dir + 'train.csv'\n",
    "train_dir = data_dir + 'train/'\n",
    "\n",
    "train = pd.read_csv(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KagglePEDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Kaggle PE dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.pedataframe = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" Return number of 2D images. (Each CT slice is an independent image.)\"\"\"\n",
    "        return len(self.pedataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                train.StudyInstanceUID[idx],\n",
    "                                train.SeriesInstanceUID[idx],\n",
    "                                train.SOPInstanceUID[idx] + '.dcm')\n",
    "        dicom_image = pydicom.dcmread(img_name) \n",
    "        image = dicom_image.pixel_array\n",
    "        \n",
    "        # in OSIC we find outside-scanner-regions with raw-values of -2000. \n",
    "        # Let's threshold between air (0) and this default (-2000) using -1000\n",
    "        image[image <= -1000] = 0\n",
    "        \n",
    "        # convert to HU using DICOM information\n",
    "        # HU is a number between -1000 and 1000 (generally)\n",
    "        # good lung tissue is between -950 and -700 (approximately)\n",
    "        intercept = dicom_image.RescaleIntercept\n",
    "        slope = dicom_image.RescaleSlope\n",
    "        \n",
    "        if slope != 1:\n",
    "            image = slope * image.astype(np.float64)\n",
    "            \n",
    "        image = image.astype(np.int16)\n",
    "        image += np.int16(intercept)\n",
    "        \n",
    "        # Convert image from numpy array to PIL image (so that we can use pytorch transforms)\n",
    "        image[image >= 500] = 500\n",
    "        image[image <= -1000] = -1000\n",
    "        image = (image + 1000)/1500\n",
    "        image = image*255\n",
    "        image = np.uint8(image)\n",
    "        image = PIL.Image.fromarray(image).convert('RGB')\n",
    "\n",
    "        # image is 512x512 RGB PIL image\n",
    "        # pe_present_on_image is 0 or 1\n",
    "        sample = {'image': image, \n",
    "                  'pe_present_on_image': int(train.pe_present_on_image[idx])}\n",
    "\n",
    "        # Only apply transform to image.\n",
    "        if self.transform:\n",
    "            sample['image'] = self.transform(sample['image'])\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "\n",
    "from skimage.color import gray2rgb\n",
    "import functools\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import pydicom\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = 111.6126708984375\n",
    "global_std = 79.95233637352047\n",
    "\n",
    "transform=T.Compose([T.Resize(256),\n",
    "                     T.RandomCrop(224),\n",
    "                     T.ToTensor(),\n",
    "                     T.Normalize(mean=[global_mean, global_mean, global_mean], \n",
    "                                          std=[global_std, global_std, global_std]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = KagglePEDataset(csv_file=train_csv, root_dir=train_dir,\n",
    "                                           transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.classifier._modules['6'] = nn.Linear(4096, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paralleize model \n",
    "vgg16.cuda()\n",
    "        \n",
    "# use network for evaluation \n",
    "vgg16.eval()\n",
    "\n",
    "testloader = DataLoader(transformed_dataset, batch_size=1, num_workers=1)\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad(): # Always call no_grad() when evaluating model (remove for training)\n",
    "    for batch_idx, sample_batched in enumerate(testloader):\n",
    "        data = torch.autograd.Variable(sample_batched['image'].cuda()), \n",
    "        target = torch.autograd.Variable(sample_batched['pe_present_on_image'].cuda())\n",
    "\n",
    "        # forward\n",
    "        output = vgg16(data[0].float())\n",
    "        assert output.shape[1] == 2 # output shape is 1x2\n",
    "\n",
    "        pred = output.data.max(1)[1]\n",
    "\n",
    "        correct += pred.eq(target.data).sum()\n",
    "        #print(correct)\n",
    "        if batch_idx % 100 == 0 and batch_idx != 0:\n",
    "            break\n",
    "            # break early so I don't take forever, I'm just doing sanity check here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on untrained model:  0.23\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on untrained model: ', correct.item()/batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
